{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex3 - Getting and Knowing your Data\n",
    "\n",
    "Check out [Occupation Exercises Video Tutorial](https://www.youtube.com/watch?v=W8AB5s-L3Rw&list=PLgJhDSE2ZLxaY_DigHeiIDC1cD09rXgJv&index=4) to watch a data scientist go through the exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we are going to pull data directly from the internet.\n",
    "Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/03/15 22:17:08 WARN Utils: Your hostname, Mark resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/15 22:17:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/15 22:17:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.255.255.254:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff46e0d6a50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "spark = SparkSession.Builder().getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user\"\n",
    "spark.sparkContext.addFile(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Assign it to a variable called users and use the 'user_id' as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+--------+\n",
      "|user_id|age|gender|occupation|zip_code|\n",
      "+-------+---+------+----------+--------+\n",
      "|      1| 24|     M|technician|   85711|\n",
      "|      2| 53|     F|     other|   94043|\n",
      "|      3| 23|     M|    writer|   32067|\n",
      "|      4| 24|     M|technician|   43537|\n",
      "|      5| 33|     F|     other|   15213|\n",
      "+-------+---+------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark doesn't have an index.\n",
    "users = spark.read.csv(f\"file:///{SparkFiles.get('u.user')}\", sep=\"|\", header=True)\n",
    "users.show(5)\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+--------+\n",
      "|user_id|age|gender|occupation|zip_code|\n",
      "+-------+---+------+----------+--------+\n",
      "|      1| 24|     M|technician|   85711|\n",
      "|      2| 53|     F|     other|   94043|\n",
      "|      3| 23|     M|    writer|   32067|\n",
      "+-------+---+------+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = users.withColumns(\n",
    "    {\n",
    "        \"user_id\": F.col(\"user_id\").cast(T.IntegerType()),\n",
    "        \"age\": F.col(\"age\").cast(T.IntegerType()),\n",
    "        # \"gender\": F.col(\"gender\").cast(T.StringType()),\n",
    "        # \"occupation\": F.col(\"occupation\").cast(T.StringType()),\n",
    "        # \"zip_code\": F.col(\"zip_code\").cast(T.StringType()),\n",
    "    }\n",
    ")\n",
    "users.show(3)\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. See the first 25 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|      1| 24|     M|   technician|   85711|\n",
      "|      2| 53|     F|        other|   94043|\n",
      "|      3| 23|     M|       writer|   32067|\n",
      "|      4| 24|     M|   technician|   43537|\n",
      "|      5| 33|     F|        other|   15213|\n",
      "|      6| 42|     M|    executive|   98101|\n",
      "|      7| 57|     M|administrator|   91344|\n",
      "|      8| 36|     M|administrator|   05201|\n",
      "|      9| 29|     M|      student|   01002|\n",
      "|     10| 53|     M|       lawyer|   90703|\n",
      "|     11| 39|     F|        other|   30329|\n",
      "|     12| 28|     F|        other|   06405|\n",
      "|     13| 47|     M|     educator|   29206|\n",
      "|     14| 45|     M|    scientist|   55106|\n",
      "|     15| 49|     F|     educator|   97301|\n",
      "|     16| 21|     M|entertainment|   10309|\n",
      "|     17| 30|     M|   programmer|   06355|\n",
      "|     18| 35|     F|        other|   37212|\n",
      "|     19| 40|     M|    librarian|   02138|\n",
      "|     20| 42|     F|    homemaker|   95660|\n",
      "|     21| 26|     M|       writer|   30068|\n",
      "|     22| 25|     M|       writer|   40206|\n",
      "|     23| 30|     F|       artist|   48197|\n",
      "|     24| 21|     F|       artist|   94533|\n",
      "|     25| 39|     M|     engineer|   55107|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. See the last 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|    943| 22|     M|      student|   77841|\n",
      "|    942| 48|     F|    librarian|   78209|\n",
      "|    941| 20|     M|      student|   97229|\n",
      "|    940| 32|     M|administrator|   02215|\n",
      "|    939| 26|     F|      student|   33319|\n",
      "|    938| 38|     F|   technician|   55038|\n",
      "|    937| 48|     M|     educator|   98072|\n",
      "|    936| 24|     M|        other|   32789|\n",
      "|    935| 42|     M|       doctor|   66221|\n",
      "|    934| 61|     M|     engineer|   22902|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.orderBy(F.desc(\"user_id\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. What is the number of observations in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/15 22:17:21 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users.count() = 943\n",
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{users.count() = }\")\n",
    "\n",
    "(\n",
    "    users.groupBy(\"user_id\")\n",
    "    .agg(F.count(\"user_id\").alias(\"count\"))\n",
    "    .where(F.col(\"count\") != 1)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. What is the number of columns in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Print the name of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'age', 'gender', 'occupation', 'zip_code']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. How is the dataset indexed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"the index\" (aka \"the labels\")\n",
    "# Spark doesn't have an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10. What is the data type of each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11. Print only the occupation column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|user_id|   occupation|\n",
      "+-------+-------------+\n",
      "|      1|   technician|\n",
      "|      2|        other|\n",
      "|      3|       writer|\n",
      "|      4|   technician|\n",
      "|      5|        other|\n",
      "|      6|    executive|\n",
      "|      7|administrator|\n",
      "|      8|administrator|\n",
      "|      9|      student|\n",
      "|     10|       lawyer|\n",
      "|     11|        other|\n",
      "|     12|        other|\n",
      "|     13|     educator|\n",
      "|     14|    scientist|\n",
      "|     15|     educator|\n",
      "|     16|entertainment|\n",
      "|     17|   programmer|\n",
      "|     18|        other|\n",
      "|     19|    librarian|\n",
      "|     20|    homemaker|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.select(\"user_id\", \"occupation\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12. How many different occupations are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|occupation_count|\n",
      "+----------------+\n",
      "|              21|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.select(F.count_distinct(\"occupation\").alias(\"occupation_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13. What is the most frequent occupation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|occupation|count|\n",
      "+----------+-----+\n",
      "|   student|  196|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    users.groupBy(\"occupation\")\n",
    "    .agg(F.count(\"occupation\").alias(\"count\"))\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "    .limit(1)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    users.groupBy(\"occupation\")\n",
    "    .agg(F.count(\"occupation\").alias(\"count\"))\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "    .limit(1)\n",
    "    .collect()[0][\"count\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14. Summarize the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+-----------------+---+----+----+----+---+\n",
      "|count|              avg|              std|min| 25%| 50%| 75%|max|\n",
      "+-----+-----------------+-----------------+---+----+----+----+---+\n",
      "|  943|34.05196182396607|12.19273973305903|  7|25.0|31.0|43.0| 73|\n",
      "+-----+-----------------+-----------------+---+----+----+----+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count': 943,\n",
       " 'avg': 34.05196182396607,\n",
       " 'std': 12.19273973305903,\n",
       " 'min': 7,\n",
       " '25%': 25.0,\n",
       " '50%': 31.0,\n",
       " '75%': 43.0,\n",
       " 'max': 73}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = users.select(\n",
    "    *[\n",
    "        op(\"age\").alias(name)\n",
    "        for op, name in [\n",
    "            (F.count, \"count\"),\n",
    "            (F.avg, \"avg\"),\n",
    "            (F.std, \"std\"),\n",
    "            (F.min, \"min\"),\n",
    "            (lambda col: F.percentile(col, 0.25), \"25%\"),\n",
    "            (lambda col: F.percentile(col, 0.5), \"50%\"),\n",
    "            (lambda col: F.percentile(col, 0.75), \"75%\"),\n",
    "            (F.max, \"max\"),\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "summary.show()\n",
    "summary.collect()[0].asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|              age|\n",
      "+-------+-----------------+\n",
      "|  count|              943|\n",
      "|   mean|34.05196182396607|\n",
      "| stddev|12.19273973305903|\n",
      "|    min|                7|\n",
      "|    25%|               25|\n",
      "|    50%|               31|\n",
      "|    75%|               43|\n",
      "|    max|               73|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.select(\"age\").summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15. Summarize all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------+-------+----+-----------------+------------------+-------------+-------+-------+-------+------+\n",
      "|     field|count|unique|    top|freq|              avg|               std|          min|    25%|    50%|    75%|   max|\n",
      "+----------+-----+------+-------+----+-----------------+------------------+-------------+-------+-------+-------+------+\n",
      "|       age|  943|    61|     30|  39|34.05196182396607|12.192739733059032|            7|   25.0|   31.0|   43.0|    73|\n",
      "|    gender|  943|     2|      M| 670|             NULL|              NULL|            F|   NULL|   NULL|   NULL|     M|\n",
      "|occupation|  943|    21|student| 196|             NULL|              NULL|administrator|   NULL|   NULL|   NULL|writer|\n",
      "|  zip_code|  943|   795|  55414|   9|50868.78810810811|30891.373254138154|        00000|21227.0|53711.0|78741.0| Y1A6B|\n",
      "+----------+-----+------+-------+----+-----------------+------------------+-------------+-------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = [\n",
    "    (\n",
    "        users.select(\n",
    "            F.count(col).alias(\"count\"),\n",
    "            F.count_distinct(col).alias(\"unique\"),\n",
    "            F.mode(col).alias(\"top\"),\n",
    "            F.count_if(\n",
    "                F.col(col)\n",
    "                == (\n",
    "                    users.groupBy(col)\n",
    "                    .agg(F.count(col).alias(\"count\"))\n",
    "                    .orderBy(F.desc(\"count\"))\n",
    "                    .collect()[0][col]\n",
    "                )\n",
    "            ).alias(\"freq\"),\n",
    "            F.avg(col).alias(\"avg\"),\n",
    "            F.std(col).alias(\"std\"),\n",
    "            F.min(col).alias(\"min\"),\n",
    "            F.percentile(col, 0.25).alias(\"25%\"),\n",
    "            F.percentile(col, 0.5).alias(\"50%\"),\n",
    "            F.percentile(col, 0.75).alias(\"75%\"),\n",
    "            F.max(col).alias(\"max\"),\n",
    "        ).withColumn(\"field\", F.lit(col))\n",
    "    )\n",
    "    for col in [\"age\", \"gender\", \"occupation\", \"zip_code\"]\n",
    "]\n",
    "\n",
    "reduce(lambda a, b: a.union(b), dfs).select(\n",
    "    \"field\", *[col for col in dfs[0].columns if col != \"field\"]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16. Summarize only the occupation column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+----+\n",
      "|count|unique|    top|freq|\n",
      "+-----+------+-------+----+\n",
      "|  943|    21|student| 196|\n",
      "+-----+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    users.select(\n",
    "        F.count(\"occupation\").alias(\"count\"),\n",
    "        F.countDistinct(\"occupation\").alias(\"unique\"),\n",
    "        F.mode(\"occupation\").alias(\"top\"),\n",
    "        F.count_if(\n",
    "            F.col(\"occupation\")\n",
    "            == (\n",
    "                users.groupBy(\"occupation\")\n",
    "                .agg(F.count(\"occupation\").alias(\"count\"))\n",
    "                .orderBy(F.desc(\"count\"))\n",
    "                .limit(1)\n",
    "                .collect()[0][\"occupation\"]\n",
    "            )\n",
    "        ).alias(\"freq\"),\n",
    "    )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 17. What is the mean age of users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         avg(age)|\n",
      "+-----------------+\n",
      "|34.05196182396607|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.select(F.avg(\"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 18. What is the age with least occurrence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "|  7|    1|\n",
      "| 10|    1|\n",
      "| 73|    1|\n",
      "| 11|    1|\n",
      "| 66|    1|\n",
      "| 64|    2|\n",
      "+---+-----+\n",
      "only showing top 6 rows\n",
      "\n",
      "1\n",
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "|  7|    1|\n",
      "| 10|    1|\n",
      "| 11|    1|\n",
      "| 66|    1|\n",
      "| 73|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_age = (\n",
    "    users.groupBy(\"age\").agg(F.count(\"age\").alias(\"count\")).orderBy(F.asc(\"count\"))\n",
    ")\n",
    "grouped_age.show(6)\n",
    "\n",
    "lowest_count = grouped_age.select(F.min(\"count\").alias(\"min\")).collect()[0][\"min\"]\n",
    "print(lowest_count)\n",
    "\n",
    "(\n",
    "    users.groupBy(\"age\")\n",
    "    .agg(F.count(\"age\").alias(\"count\"))\n",
    "    .where(F.col(\"count\") == lowest_count)\n",
    "    .orderBy(F.asc(\"age\"))\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
